#!/usr/bin/env python3
"""
ÔøΩ Inspetor Completo do Banco Qdrant
Ferramenta √∫nica para visualizar estrutura, metadados e conte√∫do dos pontos armazenados
Combina funcionalidades de inspe√ß√£o, decodifica√ß√£o e visualiza√ß√£o detalhada
"""

import sqlite3
import pickle
import base64
import json
import argparse
from pathlib import Path

def inspect_database_structure():
    """Inspeciona estrutura b√°sica do banco"""
    db_path = Path("qdrantDB/collection/pf_normativos/storage.sqlite")

    if not db_path.exists():
        print("‚ùå Arquivo n√£o encontrado:", db_path)
        return False

    print("üîç Estrutura do Banco Qdrant")
    print("="*50)

    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # Tabelas
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()
        print(f"üìã Tabelas: {[t[0] for t in tables]}")

        # Estrutura da tabela points
        cursor.execute("PRAGMA table_info(points);")
        columns = cursor.fetchall()
        print(f"üèóÔ∏è Colunas da tabela 'points':")
        for col in columns:
            print(f"   - {col[1]}: {col[2]}")

        # Estat√≠sticas b√°sicas
        cursor.execute("SELECT COUNT(*) FROM points;")
        total = cursor.fetchone()[0]
        print(f"üìä Total de pontos: {total:,}")

        # Tamanho do arquivo
        file_size = db_path.stat().st_size
        print(f"üíæ Tamanho: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")

        # Metadados da cole√ß√£o
        meta_path = Path("qdrantDB/meta.json")
        if meta_path.exists():
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta = json.load(f)
                if 'collections' in meta and 'pf_normativos' in meta['collections']:
                    config = meta['collections']['pf_normativos']
                    print(f"üßÆ Dimens√µes do vetor: {config.get('vectors', {}).get('size', 'N/A')}")
                    print(f"üéØ Dist√¢ncia: {config.get('vectors', {}).get('distance', 'N/A')}")

        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå Erro ao inspecionar: {e}")
        return False

def analyze_chunk_structure():
    """Analisa estrutura detalhada dos chunks armazenados"""
    db_path = Path("qdrantDB/collection/pf_normativos/storage.sqlite")

    if not db_path.exists():
        print("‚ùå Arquivo n√£o encontrado:", db_path)
        return False

    print("üß© ESTRUTURA DETALHADA DOS CHUNKS")
    print("="*60)

    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # An√°lise de uma amostra de chunks
        cursor.execute("SELECT point FROM points LIMIT 10;")
        sample_points = cursor.fetchall()

        # Estruturas encontradas
        chunk_structures = {}
        payload_fields = {}
        metadata_fields = {}
        text_lengths = []
        vector_dimensions = []

        print("üîç Analisando estrutura de 10 chunks de exemplo...")

        for i, (point_blob,) in enumerate(sample_points, 1):
            try:
                point_data = pickle.loads(point_blob)

                # Estrutura b√°sica do ponto
                point_type = type(point_data).__name__
                chunk_structures[point_type] = chunk_structures.get(point_type, 0) + 1

                # An√°lise do payload
                if hasattr(point_data, 'payload') and point_data.payload:
                    for key in point_data.payload.keys():
                        payload_fields[key] = payload_fields.get(key, 0) + 1

                    # An√°lise espec√≠fica do page_content (texto do chunk)
                    if 'page_content' in point_data.payload:
                        text = point_data.payload['page_content']
                        text_lengths.append(len(text))

                    # An√°lise dos metadados
                    if 'metadata' in point_data.payload:
                        metadata = point_data.payload['metadata']
                        if isinstance(metadata, dict):
                            for meta_key in metadata.keys():
                                metadata_fields[meta_key] = metadata_fields.get(meta_key, 0) + 1

                # An√°lise do vetor
                if hasattr(point_data, 'vector') and point_data.vector:
                    if isinstance(point_data.vector, dict) and 'vector' in point_data.vector:
                        vector = point_data.vector['vector']
                    elif isinstance(point_data.vector, list):
                        vector = point_data.vector
                    else:
                        vector = point_data.vector

                    if isinstance(vector, list):
                        vector_dimensions.append(len(vector))

            except Exception as e:
                print(f"  ‚ö†Ô∏è Erro no chunk {i}: {e}")

        # Relat√≥rio da estrutura
        print(f"\nüìä ESTRUTURA DOS CHUNKS:")
        print(f"="*40)

        print(f"üèóÔ∏è Tipos de pontos encontrados:")
        for ptype, count in chunk_structures.items():
            print(f"  - {ptype}: {count} ocorr√™ncias")

        print(f"\nüìã Campos do payload (n√≠vel raiz):")
        for field, count in sorted(payload_fields.items(), key=lambda x: x[1], reverse=True):
            print(f"  - {field}: {count}/10 chunks")

        print(f"\nüè∑Ô∏è Campos dos metadados:")
        for field, count in sorted(metadata_fields.items(), key=lambda x: x[1], reverse=True)[:15]:
            print(f"  - {field}: {count}/10 chunks")
        if len(metadata_fields) > 15:
            print(f"  ... e mais {len(metadata_fields) - 15} campos")

        if text_lengths:
            avg_text = sum(text_lengths) / len(text_lengths)
            print(f"\nüìÑ Tamanho do texto (page_content):")
            print(f"  - M√©dia: {avg_text:.0f} caracteres")
            print(f"  - M√≠nimo: {min(text_lengths)} caracteres")
            print(f"  - M√°ximo: {max(text_lengths)} caracteres")

        if vector_dimensions:
            print(f"\nüî¢ Dimens√µes dos vetores:")
            print(f"  - Dimens√µes: {vector_dimensions[0]} (todos iguais)")
            print(f"  - Tipo: embeddings densos (float32)")

        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå Erro na an√°lise: {e}")
        return False

def show_chunk_examples(full_text=False):
    """Mostra exemplos detalhados de chunks com diferentes estruturas"""
    db_path = Path("qdrantDB/collection/pf_normativos/storage.sqlite")

    if not db_path.exists():
        print("‚ùå Arquivo n√£o encontrado:", db_path)
        return False

    print("üìã EXEMPLOS DE CHUNKS ARMAZENADOS")
    if full_text:
        print("üìÑ Modo: TEXTO COMPLETO")
    else:
        print("üìÑ Modo: TEXTO TRUNCADO (use --full-text para ver completo)")
    print("="*50)

    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # Buscar chunks com diferentes n√≠veis hier√°rquicos
        cursor.execute("SELECT id, point FROM points LIMIT 3;")
        examples = cursor.fetchall()

        for i, (encoded_id, point_blob) in enumerate(examples, 1):
            print(f"\nüß© CHUNK {i}")
            print("-" * 30)

            # Decodificar
            decoded_id = pickle.loads(base64.b64decode(encoded_id))
            point_data = pickle.loads(point_blob)

            print(f"üÜî ID: {decoded_id}")

            # Estrutura do chunk
            if hasattr(point_data, 'payload') and point_data.payload:
                payload = point_data.payload

                # Texto do chunk
                if 'page_content' in payload:
                    text = payload['page_content']
                    if full_text:
                        print(f"üìÑ Texto completo:\n{text}")
                    else:
                        preview = text[:150] + "..." if len(text) > 150 else text
                        print(f"üìÑ Texto: {preview}")
                    print(f"    Tamanho: {len(text)} caracteres")

                # Metadados hier√°rquicos
                if 'metadata' in payload and isinstance(payload['metadata'], dict):
                    metadata = payload['metadata']

                    # Informa√ß√µes hier√°rquicas
                    if 'nivel' in metadata:
                        print(f"üèóÔ∏è N√≠vel: {metadata['nivel']}")
                    if 'rotulo' in metadata:
                        print(f"üè∑Ô∏è R√≥tulo: {metadata['rotulo']}")
                    if 'caminho_hierarquico' in metadata:
                        print(f"üóÇÔ∏è Caminho: {metadata['caminho_hierarquico']}")

                    # Informa√ß√µes do documento
                    if 'origem_pdf' in metadata:
                        origem = metadata['origem_pdf']
                        if isinstance(origem, dict) and 'arquivo' in origem:
                            print(f"üìÅ Arquivo: {origem['arquivo']}")
                            if 'paginas' in origem:
                                print(f"üìÑ P√°ginas: {len(origem['paginas'])} p√°ginas")

                    # Tokens e tamanho
                    if 'tokens_estimados' in metadata:
                        print(f"üî§ Tokens: {metadata['tokens_estimados']}")

            # Vetor
            if hasattr(point_data, 'vector'):
                if isinstance(point_data.vector, dict) and 'vector' in point_data.vector:
                    vector = point_data.vector['vector']
                elif isinstance(point_data.vector, list):
                    vector = point_data.vector
                else:
                    vector = point_data.vector

                if isinstance(vector, list):
                    print(f"üî¢ Embedding: {len(vector)}D [{vector[0]:.6f}, {vector[1]:.6f}, ...]")

        conn.close()
        return True

    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return False

def show_point_details(limit=2, full_text=False):
    """Mostra detalhes completos de alguns pontos"""

    db_path = Path("qdrantDB/collection/pf_normativos/storage.sqlite")

    if not db_path.exists():
        print("‚ùå Arquivo n√£o encontrado:", db_path)
        return

    print("üìä Visualizando conte√∫do detalhado dos pontos...")
    if full_text:
        print("üìÑ Modo: TEXTO COMPLETO")
    else:
        print("üìÑ Modo: TEXTO TRUNCADO (use --full-text para ver completo)")
    print("="*70)

    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # Pegar alguns registros para an√°lise detalhada
        cursor.execute("SELECT id, point FROM points LIMIT ?;", (limit,))
        records = cursor.fetchall()

        for i, (encoded_id, point_blob) in enumerate(records, 1):
            print(f"\nüîç PONTO {i}")
            print("="*50)

            # Decodificar ID
            decoded_id = pickle.loads(base64.b64decode(encoded_id))
            print(f"üÜî ID: {decoded_id}")

            # Decodificar ponto completo
            point_data = pickle.loads(point_blob)

            print(f"üìù Tipo: {type(point_data).__name__}")
            print(f"üÜî Point ID: {point_data.id}")

            # Mostrar vetor (apenas dimens√µes por ser muito grande)
            if hasattr(point_data, 'vector') and point_data.vector:
                if isinstance(point_data.vector, dict) and 'vector' in point_data.vector:
                    vector = point_data.vector['vector']
                elif isinstance(point_data.vector, list):
                    vector = point_data.vector
                else:
                    vector = point_data.vector

                if isinstance(vector, list):
                    print(f"üî¢ Vetor: {len(vector)} dimens√µes")
                    print(f"   Primeiros 5 valores: {vector[:5]}")
                    print(f"   √öltimos 5 valores: {vector[-5:]}")
                else:
                    print(f"üî¢ Vetor: {type(vector)}")

            # Mostrar payload (metadados)
            if hasattr(point_data, 'payload') and point_data.payload:
                print(f"\nüìã Payload (metadados):")
                payload = point_data.payload

                for key, value in payload.items():
                    if key == 'page_content' and isinstance(value, str):
                        # Mostrar texto do chunk
                        if full_text:
                            print(f"  üìÑ {key} (completo):\n{value}")
                        else:
                            preview = value[:200] + "..." if len(value) > 200 else value
                            print(f"  üìÑ {key}: {preview}")
                    elif key == 'chunk_text' and isinstance(value, str):
                        # Mostrar apenas in√≠cio do texto (campo legado)
                        if full_text:
                            print(f"  üìÑ {key} (completo):\n{value}")
                        else:
                            preview = value[:200] + "..." if len(value) > 200 else value
                            print(f"  üìÑ {key}: {preview}")
                    elif key == 'metadata' and isinstance(value, dict):
                        print(f"  üìä {key}:")
                        for meta_key, meta_value in value.items():
                            if isinstance(meta_value, str) and len(meta_value) > 100 and not full_text:
                                preview = meta_value[:100] + "..."
                                print(f"    - {meta_key}: {preview}")
                            else:
                                print(f"    - {meta_key}: {meta_value}")
                    else:
                        if isinstance(value, str) and len(value) > 200 and not full_text:
                            preview = value[:200] + "..."
                            print(f"  üè∑Ô∏è {key}: {preview}")
                        else:
                            print(f"  üè∑Ô∏è {key}: {value}")

            print(f"\nüíæ Tamanho total: {len(point_blob):,} bytes")

        # Mostrar estat√≠sticas dos payloads
        print(f"\nüìà ESTAT√çSTICAS GERAIS")
        print("="*30)

        # Contar campos mais comuns nos payloads
        cursor.execute("SELECT point FROM points LIMIT 100;")  # Amostra de 100
        sample_records = cursor.fetchall()

        payload_keys = {}
        for point_blob, in sample_records:
            try:
                point_data = pickle.loads(point_blob)
                if hasattr(point_data, 'payload') and point_data.payload:
                    for key in point_data.payload.keys():
                        payload_keys[key] = payload_keys.get(key, 0) + 1
            except:
                continue

        print(f"üè∑Ô∏è Campos mais comuns nos payloads (amostra de 100):")
        for key, count in sorted(payload_keys.items(), key=lambda x: x[1], reverse=True):
            print(f"  - {key}: {count} ocorr√™ncias")

        conn.close()

    except Exception as e:
        print(f"‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Inspetor Completo do Banco Qdrant")
    parser.add_argument("--mode", choices=["structure", "details", "chunks", "examples", "all"], default="all",
                       help="Modo: structure (estrutura), details (pontos), chunks (an√°lise chunks), examples (exemplos), all (tudo)")
    parser.add_argument("--limit", type=int, default=2,
                       help="N√∫mero de pontos para mostrar em detalhes (padr√£o: 2)")
    parser.add_argument("--full-text", action="store_true",
                       help="Mostrar texto completo dos chunks sem truncamento")

    args = parser.parse_args()

    if args.mode in ["structure", "all"]:
        if not inspect_database_structure():
            exit(1)

    if args.mode in ["chunks", "all"]:
        if args.mode == "all":
            print("\n" + "="*70)
        analyze_chunk_structure()

    if args.mode in ["examples", "all"]:
        if args.mode in ["all", "chunks"]:
            print("\n" + "="*70)
        show_chunk_examples(full_text=args.full_text)

    if args.mode in ["details", "all"]:
        if args.mode == "all":
            print("\n" + "="*70)
        show_point_details(args.limit, full_text=args.full_text)